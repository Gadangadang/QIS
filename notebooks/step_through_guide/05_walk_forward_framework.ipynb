{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from core.multi_asset_loader import load_assets\n",
    "from core.multi_asset_signal import SingleAssetWrapper\n",
    "from signals.momentum import MomentumSignalV2\n",
    "from core.portfolio_manager import PortfolioConfig\n",
    "from backtest.backtest_engine import run_multi_asset_backtest\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08445d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Walk-Forward Methodology\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  ROLLING WINDOW                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Window 1:\n",
    "â”œâ”€ Train: 2010-2012 (2 years) â†’ Pick best params\n",
    "â””â”€ Test:  2013      (1 year)  â†’ Trade with those params\n",
    "\n",
    "Window 2:\n",
    "â”œâ”€ Train: 2011-2013 (2 years) â†’ Pick NEW best params\n",
    "â””â”€ Test:  2014      (1 year)  â†’ Trade with NEW params\n",
    "\n",
    "Window 3:\n",
    "â”œâ”€ Train: 2012-2014 (2 years) â†’ Pick NEW best params\n",
    "â””â”€ Test:  2015      (1 year)  â†’ Trade with NEW params\n",
    "\n",
    "...\n",
    "\n",
    "Key Rules:\n",
    "1. NEVER use test data in training\n",
    "2. NEVER reuse parameters from previous window\n",
    "3. Optimize ONLY on train period\n",
    "4. Trade ONLY with those params in test period\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cbdc6b",
   "metadata": {},
   "source": [
    "## Step 1: Define Walk-Forward Splits\n",
    "\n",
    "**Goal:** Split data into non-overlapping train/test windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e48a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_forward_splits(\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    train_years: int = 2,\n",
    "    test_years: int = 1\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Create rolling windows for walk-forward testing.\n",
    "    \n",
    "    Returns list of dicts:\n",
    "    [\n",
    "        {'train_start': '2010-01-01', 'train_end': '2011-12-31',\n",
    "         'test_start': '2012-01-01', 'test_end': '2012-12-31'},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "    current_train_start = pd.Timestamp(start_date)\n",
    "    final_date = pd.Timestamp(end_date)\n",
    "    \n",
    "    while True:\n",
    "        # Train period\n",
    "        train_end = current_train_start + pd.DateOffset(years=train_years)\n",
    "        \n",
    "        # Test period\n",
    "        test_start = train_end + pd.DateOffset(days=1)\n",
    "        test_end = test_start + pd.DateOffset(years=test_years)\n",
    "        \n",
    "        # Stop if we exceed final date\n",
    "        if test_end > final_date:\n",
    "            break\n",
    "        \n",
    "        splits.append({\n",
    "            'train_start': current_train_start.strftime('%Y-%m-%d'),\n",
    "            'train_end': train_end.strftime('%Y-%m-%d'),\n",
    "            'test_start': test_start.strftime('%Y-%m-%d'),\n",
    "            'test_end': test_end.strftime('%Y-%m-%d')\n",
    "        })\n",
    "        \n",
    "        # Roll forward by test period\n",
    "        current_train_start = test_start\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Create splits\n",
    "splits = create_walk_forward_splits(\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-12-31',\n",
    "    train_years=2,\n",
    "    test_years=1\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“… Walk-Forward Splits:\")\n",
    "print(f\"\\nTotal Windows: {len(splits)}\\n\")\n",
    "for i, split in enumerate(splits, 1):\n",
    "    print(f\"Window {i}:\")\n",
    "    print(f\"  Train: {split['train_start']} to {split['train_end']}\")\n",
    "    print(f\"  Test:  {split['test_start']} to {split['test_end']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc1975",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Parameter Grid\n",
    "\n",
    "**Define parameters to test in each training window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for momentum strategy\n",
    "param_grid = {\n",
    "    'lookback': [60, 90, 120, 150],\n",
    "    'sma_filter': [150, 200, 250]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "from itertools import product\n",
    "\n",
    "param_combinations = [\n",
    "    {'lookback': lb, 'sma_filter': sma}\n",
    "    for lb, sma in product(param_grid['lookback'], param_grid['sma_filter'])\n",
    "]\n",
    "\n",
    "print(\"\\nâš™ï¸ Parameter Grid:\")\n",
    "print(f\"\\nTotal Combinations: {len(param_combinations)}\\n\")\n",
    "print(\"Sample combinations:\")\n",
    "for params in param_combinations[:5]:\n",
    "    print(f\"  Lookback={params['lookback']}, SMA={params['sma_filter']}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c6bc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Train - Optimize on Training Data\n",
    "\n",
    "**For ONE window, test all parameter combinations on training period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf16112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters(\n",
    "    train_split: Dict,\n",
    "    param_combinations: List[Dict],\n",
    "    tickers: List[str]\n",
    ") -> Tuple[Dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Test all parameter combinations on training data.\n",
    "    Return best params and all results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ” Optimizing on {train_split['train_start']} to {train_split['train_end']}\")\n",
    "    \n",
    "    # Load training data\n",
    "    train_prices = load_assets(\n",
    "        tickers=tickers,\n",
    "        start_date=train_split['train_start'],\n",
    "        end_date=train_split['train_end']\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        # Generate signals with these params\n",
    "        signal_gen = MomentumSignalV2(\n",
    "            lookback=params['lookback'],\n",
    "            sma_filter=params['sma_filter']\n",
    "        )\n",
    "        multi_signal = SingleAssetWrapper(signal_gen)\n",
    "        signals = multi_signal.generate(train_prices)\n",
    "        \n",
    "        # Run backtest\n",
    "        config = PortfolioConfig(initial_capital=100000)\n",
    "        result = run_multi_asset_backtest(train_prices, signals, config)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'lookback': params['lookback'],\n",
    "            'sma_filter': params['sma_filter'],\n",
    "            'sharpe': result.metrics['sharpe_ratio'],\n",
    "            'total_return': result.metrics['total_return'],\n",
    "            'max_dd': result.metrics['max_drawdown'],\n",
    "            'win_rate': result.metrics['win_rate']\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('sharpe', ascending=False)\n",
    "    best_params = results_df.iloc[0][['lookback', 'sma_filter']].to_dict()\n",
    "    \n",
    "    print(f\"\\nâœ… Best Parameters:\")\n",
    "    print(f\"   Lookback: {best_params['lookback']}\")\n",
    "    print(f\"   SMA Filter: {best_params['sma_filter']}\")\n",
    "    print(f\"   Sharpe: {results_df.iloc[0]['sharpe']:.2f}\")\n",
    "    \n",
    "    return best_params, results_df\n",
    "\n",
    "# Example: Optimize first window\n",
    "TICKERS = ['ES=F', 'GC=F', 'NQ=F']\n",
    "best_params, train_results = optimize_parameters(splits[0], param_combinations[:3], TICKERS)  # Testing 3 for speed\n",
    "\n",
    "print(\"\\nðŸ“Š Top 3 Parameter Sets:\")\n",
    "print(train_results.head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f67d02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Test - Evaluate on Out-of-Sample Period\n",
    "\n",
    "**Use ONLY the best params from training. Trade on unseen test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7db18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameters(\n",
    "    test_split: Dict,\n",
    "    best_params: Dict,\n",
    "    tickers: List[str]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Test parameters on out-of-sample data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ§ª Testing on {test_split['test_start']} to {test_split['test_end']}\")\n",
    "    print(f\"   Using params: Lookback={best_params['lookback']}, SMA={best_params['sma_filter']}\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_prices = load_assets(\n",
    "        tickers=tickers,\n",
    "        start_date=test_split['test_start'],\n",
    "        end_date=test_split['test_end']\n",
    "    )\n",
    "    \n",
    "    # Generate signals with BEST params\n",
    "    signal_gen = MomentumSignalV2(\n",
    "        lookback=int(best_params['lookback']),\n",
    "        sma_filter=int(best_params['sma_filter'])\n",
    "    )\n",
    "    multi_signal = SingleAssetWrapper(signal_gen)\n",
    "    signals = multi_signal.generate(test_prices)\n",
    "    \n",
    "    # Run backtest\n",
    "    config = PortfolioConfig(initial_capital=100000)\n",
    "    result = run_multi_asset_backtest(test_prices, signals, config)\n",
    "    \n",
    "    print(f\"\\nâœ… Out-of-Sample Results:\")\n",
    "    print(f\"   Sharpe: {result.metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   Total Return: {result.metrics['total_return']:.2%}\")\n",
    "    print(f\"   Max DD: {result.metrics['max_drawdown']:.2%}\")\n",
    "    \n",
    "    return result.metrics\n",
    "\n",
    "# Test on OOS period\n",
    "oos_metrics = test_parameters(splits[0], best_params, TICKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbe74e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Compare IS vs OOS Performance\n",
    "\n",
    "**The moment of truth: Did the strategy overfit?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IS performance (best params on training data)\n",
    "is_sharpe = train_results.iloc[0]['sharpe']\n",
    "is_return = train_results.iloc[0]['total_return']\n",
    "\n",
    "# OOS performance\n",
    "oos_sharpe = oos_metrics['sharpe_ratio']\n",
    "oos_return = oos_metrics['total_return']\n",
    "\n",
    "print(\"\\nðŸ“Š IS vs OOS Comparison:\")\n",
    "print(f\"\\n{'Metric':<20} {'In-Sample':>15} {'Out-of-Sample':>15} {'Degradation':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "sharpe_deg = (oos_sharpe - is_sharpe) / is_sharpe if is_sharpe != 0 else 0\n",
    "return_deg = (oos_return - is_return) / is_return if is_return != 0 else 0\n",
    "\n",
    "print(f\"{'Sharpe Ratio':<20} {is_sharpe:>15.2f} {oos_sharpe:>15.2f} {sharpe_deg:>14.1%}\")\n",
    "print(f\"{'Total Return':<20} {is_return:>14.2%} {oos_return:>14.2%} {return_deg:>14.1%}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Interpretation:\")\n",
    "if abs(sharpe_deg) < 0.30:\n",
    "    print(\"   âœ… GOOD: Performance degradation < 30%\")\n",
    "    print(\"   Strategy appears robust!\")\n",
    "elif abs(sharpe_deg) < 0.50:\n",
    "    print(\"   âš ï¸ MODERATE: Performance degradation 30-50%\")\n",
    "    print(\"   Some overfitting, but acceptable\")\n",
    "else:\n",
    "    print(\"   âŒ BAD: Performance degradation > 50%\")\n",
    "    print(\"   Severe overfitting detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf42da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Full Walk-Forward Engine\n",
    "\n",
    "**Run ALL windows and aggregate OOS results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12763b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_walk_forward(\n",
    "    splits: List[Dict],\n",
    "    param_combinations: List[Dict],\n",
    "    tickers: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run full walk-forward test.\n",
    "    Returns DataFrame with all window results.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for i, split in enumerate(splits, 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"WINDOW {i}/{len(splits)}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Train: Optimize parameters\n",
    "        best_params, train_results = optimize_parameters(split, param_combinations, tickers)\n",
    "        \n",
    "        # Test: Evaluate OOS\n",
    "        oos_metrics = test_parameters(split, best_params, tickers)\n",
    "        \n",
    "        # Store results\n",
    "        all_results.append({\n",
    "            'window': i,\n",
    "            'test_start': split['test_start'],\n",
    "            'test_end': split['test_end'],\n",
    "            'best_lookback': best_params['lookback'],\n",
    "            'best_sma': best_params['sma_filter'],\n",
    "            'is_sharpe': train_results.iloc[0]['sharpe'],\n",
    "            'oos_sharpe': oos_metrics['sharpe_ratio'],\n",
    "            'oos_return': oos_metrics['total_return'],\n",
    "            'oos_max_dd': oos_metrics['max_drawdown']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Note: This would take a while to run with full param grid\n",
    "# For demo, we'll show the structure\n",
    "print(\"\\nðŸ”§ Walk-Forward Engine Structure:\")\n",
    "print(\"\\nFor production use:\")\n",
    "print(\"  1. Run run_walk_forward(splits, param_combinations, TICKERS)\")\n",
    "print(\"  2. Analyze aggregate OOS performance\")\n",
    "print(\"  3. Check consistency across windows\")\n",
    "print(\"  4. Deploy if OOS Sharpe > threshold (e.g., 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b46f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Aggregate OOS Equity Curve\n",
    "\n",
    "**Stitch together OOS periods to see true performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of what aggregate OOS looks like\n",
    "print(\"\\nðŸ“ˆ Aggregate OOS Equity Curve:\")\n",
    "print(\"\\nConcept:\")\n",
    "print(\"  Window 1 OOS: $100k â†’ $110k (Jan-Dec 2022)\")\n",
    "print(\"  Window 2 OOS: $110k â†’ $118k (Jan-Dec 2023)\")\n",
    "print(\"  Window 3 OOS: $118k â†’ $125k (Jan-Dec 2024)\")\n",
    "print(\"\\n  Final OOS Return: +25%\")\n",
    "print(\"  This is your TRUE expected performance!\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Why This Matters:\")\n",
    "print(\"  âœ… Never used future data\")\n",
    "print(\"  âœ… Parameters re-optimized each window\")\n",
    "print(\"  âœ… Realistic transaction costs included\")\n",
    "print(\"  âœ… Can compare to benchmark (buy-and-hold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fbbc36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "### Walk-Forward Testing Rules:\n",
    "\n",
    "```\n",
    "DO:\n",
    "âœ… Optimize on training period only\n",
    "âœ… Test on future unseen data\n",
    "âœ… Re-optimize for each window\n",
    "âœ… Use consistent train/test split ratio\n",
    "âœ… Report aggregate OOS metrics\n",
    "\n",
    "DON'T:\n",
    "âŒ Use test data in training\n",
    "âŒ Cherry-pick good windows\n",
    "âŒ Change parameters during test period\n",
    "âŒ Ignore transaction costs\n",
    "âŒ Report in-sample results as final\n",
    "```\n",
    "\n",
    "### Performance Degradation:\n",
    "\n",
    "| IS Sharpe | OOS Sharpe | Degradation | Status |\n",
    "|-----------|------------|-------------|--------|\n",
    "| 2.0 | 1.8 | -10% | âœ… Excellent |\n",
    "| 2.0 | 1.4 | -30% | âœ… Good |\n",
    "| 2.0 | 1.0 | -50% | âš ï¸ Acceptable |\n",
    "| 2.0 | 0.5 | -75% | âŒ Overfit |\n",
    "| 2.0 | -0.5 | -125% | âŒâŒ Total failure |\n",
    "\n",
    "### Why Parameters Change:\n",
    "\n",
    "Market conditions evolve! What worked in 2020 (low vol, QE) may not work in 2022 (high vol, rate hikes).\n",
    "\n",
    "**Adaptive optimization** keeps strategy relevant.\n",
    "\n",
    "### Production Workflow:\n",
    "\n",
    "```python\n",
    "# 1. Development\n",
    "results = run_walk_forward(splits, params, tickers)\n",
    "if results['oos_sharpe'].mean() > 0.5:\n",
    "    print(\"Strategy approved for production!\")\n",
    "\n",
    "# 2. Deployment\n",
    "# - Use latest window's best params\n",
    "# - Re-optimize monthly or quarterly\n",
    "# - Monitor live vs OOS performance\n",
    "```\n",
    "\n",
    "### Critical Insights:\n",
    "\n",
    "1. **OOS is the ONLY metric that matters**\n",
    "   - In-sample tells you nothing about future\n",
    "   - Always report OOS Sharpe, never IS\n",
    "\n",
    "2. **Some degradation is normal**\n",
    "   - 20-30% drop ISâ†’OOS is expected\n",
    "   - 0% degradation suggests data leakage!\n",
    "\n",
    "3. **Consistency > Peak Performance**\n",
    "   - Prefer 0.8 Sharpe across all windows\n",
    "   - Over 2.0 Sharpe in one window, 0.2 in others\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Congratulations!\n",
    "\n",
    "You now understand:\n",
    "1. âœ… Basic backtest mechanics\n",
    "2. âœ… Portfolio manager orchestration\n",
    "3. âœ… Risk management integration\n",
    "4. âœ… Full system pipeline\n",
    "5. âœ… Walk-forward validation methodology\n",
    "\n",
    "**You're ready to:**\n",
    "- Build new strategies with confidence\n",
    "- Properly validate before deploying\n",
    "- Avoid overfitting traps\n",
    "- Present results professionally\n",
    "\n",
    "## ðŸš€ Next Steps:\n",
    "\n",
    "1. **Implement walk-forward in production**\n",
    "   - Create `walk_forward_engine.py`\n",
    "   - Add to backtest folder\n",
    "   - Test existing momentum strategy\n",
    "\n",
    "2. **Research new signals**\n",
    "   - Pairs trading (cointegration)\n",
    "   - Energy signals (contango/backwardation)\n",
    "   - Regime detection (HMM, vol regimes)\n",
    "\n",
    "3. **Build CV projects**\n",
    "   - Each with proper walk-forward validation\n",
    "   - Document methodology clearly\n",
    "   - Show OOS performance only\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Trading! ðŸ“ˆ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
