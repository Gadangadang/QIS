{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from core.taa.features.pipeline import FeaturePipeline\n",
    "from core.taa.model_engine import TAAModelEngine\n",
    "from core.data.collectors import YahooCollector\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1b471",
   "metadata": {},
   "source": [
    "## 1. Load Full Dataset (2010-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same setup as 03_model_training\n",
    "tickers = ['SPY', 'XLK', 'XLE', 'XLF', 'XLV', 'XLI', 'XLP', 'XLY', 'XLU']\n",
    "benchmark = 'ACWI'\n",
    "\n",
    "print(\"Generating features...\")\n",
    "pipeline = FeaturePipeline()\n",
    "df_features = pipeline.run(\n",
    "    tickers=tickers,\n",
    "    benchmark_ticker=benchmark,\n",
    "    start_date='2010-01-01',\n",
    "    end_date='2024-12-31'\n",
    ")\n",
    "\n",
    "print(f\"Features shape: {df_features.shape}\")\n",
    "\n",
    "# Add Close prices for target calculation\n",
    "yahoo = YahooCollector()\n",
    "prices_df = yahoo.fetch_history(tickers, '2010-01-01', '2024-12-31')\n",
    "\n",
    "close_prices = []\n",
    "for ticker in tickers:\n",
    "    ticker_prices = prices_df.xs(ticker, axis=1, level=0)['Close']\n",
    "    ticker_df = pd.DataFrame({'Close': ticker_prices})\n",
    "    ticker_df['ticker'] = ticker\n",
    "    ticker_df = ticker_df.reset_index().rename(columns={'index': 'Date'})\n",
    "    ticker_df = ticker_df.set_index(['Date', 'ticker'])\n",
    "    close_prices.append(ticker_df)\n",
    "\n",
    "close_df = pd.concat(close_prices).sort_index()\n",
    "df_full = df_features.join(close_df, how='left')\n",
    "\n",
    "# Create targets\n",
    "engine = TAAModelEngine(horizons=[1, 4, 12])\n",
    "df_with_targets = engine.create_targets(df_full, price_col='Close')\n",
    "\n",
    "print(f\"Full dataset with targets: {df_with_targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e9c90",
   "metadata": {},
   "source": [
    "## 2. Define Walk-Forward Folds\n",
    "\n",
    "Strategy: Expanding window with annual out-of-sample periods\n",
    "- Fold 1: Train 2010-2014 â†’ Test 2015\n",
    "- Fold 2: Train 2010-2016 â†’ Test 2017\n",
    "- Fold 3: Train 2010-2018 â†’ Test 2019\n",
    "- Fold 4: Train 2010-2020 â†’ Test 2021\n",
    "- Fold 5: Train 2010-2022 â†’ Test 2023\n",
    "- Fold 6: Train 2010-2023 â†’ Test 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fold boundaries\n",
    "folds = [\n",
    "    {'train_end': '2014-12-31', 'test_start': '2015-01-01', 'test_end': '2015-12-31'},\n",
    "    {'train_end': '2016-12-31', 'test_start': '2017-01-01', 'test_end': '2017-12-31'},\n",
    "    {'train_end': '2018-12-31', 'test_start': '2019-01-01', 'test_end': '2019-12-31'},\n",
    "    {'train_end': '2020-12-31', 'test_start': '2021-01-01', 'test_end': '2021-12-31'},\n",
    "    {'train_end': '2022-12-31', 'test_start': '2023-01-01', 'test_end': '2023-12-31'},\n",
    "    {'train_end': '2023-12-31', 'test_start': '2024-01-01', 'test_end': '2024-12-31'},\n",
    "]\n",
    "\n",
    "print(\"Walk-Forward Folds:\")\n",
    "for i, fold in enumerate(folds, 1):\n",
    "    print(f\"Fold {i}: Train 2010-{fold['train_end'][:4]} â†’ Test {fold['test_start'][:4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0308bf",
   "metadata": {},
   "source": [
    "## 3. Run Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Prepare feature columns\n",
    "target_cols = ['target_1w', 'target_4w', 'target_12w']\n",
    "exclude_cols = target_cols + ['Close', 'Open', 'High', 'Low', 'Volume']\n",
    "feature_cols = [c for c in df_with_targets.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features\\n\")\n",
    "\n",
    "# Store results\n",
    "oos_results = {1: [], 4: [], 12: []}  # Out-of-sample predictions by horizon\n",
    "fold_metrics = []  # IC metrics per fold\n",
    "\n",
    "for fold_idx, fold in enumerate(folds, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {fold_idx}: Train through {fold['train_end']}, Test {fold['test_start']} to {fold['test_end']}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Get dates\n",
    "    dates = df_with_targets.index.get_level_values('Date')\n",
    "    train_mask = dates <= fold['train_end']\n",
    "    test_mask = (dates >= fold['test_start']) & (dates <= fold['test_end'])\n",
    "    \n",
    "    train_data = df_with_targets[train_mask]\n",
    "    test_data = df_with_targets[test_mask]\n",
    "    \n",
    "    print(f\"Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "    \n",
    "    fold_ic = {'fold': fold_idx, 'test_year': fold['test_start'][:4]}\n",
    "    \n",
    "    # Train models for each horizon\n",
    "    for horizon in [1, 4, 12]:\n",
    "        target_col = f'target_{horizon}w'\n",
    "        pred_col = f'pred_{horizon}w'\n",
    "        \n",
    "        # Prepare train data (drop NaNs)\n",
    "        train_valid = train_data[feature_cols + [target_col]].dropna()\n",
    "        test_valid = test_data[feature_cols + [target_col]].dropna()\n",
    "        \n",
    "        if len(train_valid) == 0 or len(test_valid) == 0:\n",
    "            print(f\"  {horizon}w: Insufficient data, skipping\")\n",
    "            continue\n",
    "        \n",
    "        X_train = train_valid[feature_cols]\n",
    "        y_train = train_valid[target_col]\n",
    "        X_test = test_valid[feature_cols]\n",
    "        y_test = test_valid[target_col]\n",
    "        \n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=200,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        \n",
    "        # Predict on test set (truly out-of-sample)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate IC\n",
    "        ic = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "        \n",
    "        # Store predictions\n",
    "        oos_df = pd.DataFrame({\n",
    "            'date': X_test.index.get_level_values('Date'),\n",
    "            'ticker': X_test.index.get_level_values('ticker'),\n",
    "            'actual': y_test.values,\n",
    "            'predicted': y_pred,\n",
    "            'fold': fold_idx\n",
    "        })\n",
    "        oos_results[horizon].append(oos_df)\n",
    "        \n",
    "        # Store IC\n",
    "        fold_ic[f'ic_{horizon}w'] = ic\n",
    "        \n",
    "        print(f\"  {horizon}w: IC = {ic:.4f} (Train: {len(X_train)}, Test: {len(X_test)})\")\n",
    "    \n",
    "    fold_metrics.append(fold_ic)\n",
    "\n",
    "# Combine all out-of-sample predictions\n",
    "oos_predictions = {}\n",
    "for horizon in [1, 4, 12]:\n",
    "    oos_predictions[horizon] = pd.concat(oos_results[horizon], ignore_index=True)\n",
    "\n",
    "fold_metrics_df = pd.DataFrame(fold_metrics)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Walk-Forward Validation Complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3da0a9",
   "metadata": {},
   "source": [
    "## 4. Analyze Out-of-Sample Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display fold-by-fold IC\n",
    "print(\"\\nOut-of-Sample IC by Fold:\")\n",
    "display(fold_metrics_df)\n",
    "\n",
    "# Calculate average IC\n",
    "print(\"\\nAverage Out-of-Sample IC:\")\n",
    "for horizon in [1, 4, 12]:\n",
    "    col = f'ic_{horizon}w'\n",
    "    avg_ic = fold_metrics_df[col].mean()\n",
    "    std_ic = fold_metrics_df[col].std()\n",
    "    print(f\"{horizon}w: {avg_ic:.4f} Â± {std_ic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5256bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IC over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for horizon in [1, 4, 12]:\n",
    "    col = f'ic_{horizon}w'\n",
    "    ax.plot(fold_metrics_df['test_year'], fold_metrics_df[col], \n",
    "            marker='o', label=f'{horizon}w', linewidth=2)\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.axhline(0.05, color='green', linestyle=':', alpha=0.5, label='IC > 0.05 (Good)')\n",
    "ax.set_xlabel('Test Year')\n",
    "ax.set_ylabel('Out-of-Sample IC')\n",
    "ax.set_title('Walk-Forward IC by Year (Expanding Window)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ec270",
   "metadata": {},
   "source": [
    "## 5. Calculate Hit Rate (Directional Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7600f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hit Rate Analysis (% Correct Direction):\\n\")\n",
    "\n",
    "for horizon in [1, 4, 12]:\n",
    "    df = oos_predictions[horizon]\n",
    "    \n",
    "    # Calculate directional accuracy\n",
    "    correct_direction = np.sign(df['actual']) == np.sign(df['predicted'])\n",
    "    hit_rate = correct_direction.mean()\n",
    "    \n",
    "    # Overall IC\n",
    "    overall_ic = np.corrcoef(df['actual'], df['predicted'])[0, 1]\n",
    "    \n",
    "    print(f\"{horizon}w Horizon:\")\n",
    "    print(f\"  Hit Rate: {hit_rate:.2%}\")\n",
    "    print(f\"  Overall IC: {overall_ic:.4f}\")\n",
    "    print(f\"  Samples: {len(df)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2e17e",
   "metadata": {},
   "source": [
    "## 6. Quintile Analysis\n",
    "\n",
    "Compare actual returns for top 20% predictions vs bottom 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18420f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quintile Analysis (Top 20% vs Bottom 20% Predictions):\\n\")\n",
    "\n",
    "for horizon in [1, 4, 12]:\n",
    "    df = oos_predictions[horizon].copy()\n",
    "    \n",
    "    # Sort by predictions\n",
    "    df = df.sort_values('predicted')\n",
    "    \n",
    "    # Get top and bottom quintiles\n",
    "    n = len(df)\n",
    "    quintile_size = n // 5\n",
    "    \n",
    "    bottom_quintile = df.head(quintile_size)['actual'].mean()\n",
    "    top_quintile = df.tail(quintile_size)['actual'].mean()\n",
    "    spread = top_quintile - bottom_quintile\n",
    "    \n",
    "    print(f\"{horizon}w Horizon:\")\n",
    "    print(f\"  Bottom 20% avg actual return: {bottom_quintile:+.4f}\")\n",
    "    print(f\"  Top 20% avg actual return: {top_quintile:+.4f}\")\n",
    "    print(f\"  Spread (Top - Bottom): {spread:+.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3e78b",
   "metadata": {},
   "source": [
    "## 7. Decision: Proceed to Portfolio Construction?\n",
    "\n",
    "**Criteria for Success:**\n",
    "- âœ… Average OOS IC > 0.05 for at least one horizon\n",
    "- âœ… IC relatively stable (not declining over time)\n",
    "- âœ… Hit Rate > 52%\n",
    "- âœ… Positive quintile spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated decision logic\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL VALIDATION DECISION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "checks = []\n",
    "\n",
    "# Check 1: IC > 0.05\n",
    "for horizon in [1, 4, 12]:\n",
    "    avg_ic = fold_metrics_df[f'ic_{horizon}w'].mean()\n",
    "    if avg_ic > 0.05:\n",
    "        checks.append(f\"âœ… {horizon}w IC = {avg_ic:.4f} > 0.05\")\n",
    "        break\n",
    "else:\n",
    "    checks.append(\"âŒ No horizon has IC > 0.05\")\n",
    "\n",
    "# Check 2: Hit rate\n",
    "for horizon in [1, 4, 12]:\n",
    "    df = oos_predictions[horizon]\n",
    "    hit_rate = (np.sign(df['actual']) == np.sign(df['predicted'])).mean()\n",
    "    if hit_rate > 0.52:\n",
    "        checks.append(f\"âœ… {horizon}w Hit Rate = {hit_rate:.2%} > 52%\")\n",
    "        break\n",
    "else:\n",
    "    checks.append(\"âŒ No horizon has hit rate > 52%\")\n",
    "\n",
    "# Check 3: IC stability (coefficient of variation)\n",
    "for horizon in [1, 4, 12]:\n",
    "    col = f'ic_{horizon}w'\n",
    "    cv = fold_metrics_df[col].std() / abs(fold_metrics_df[col].mean())\n",
    "    if cv < 1.0:  # CV < 1 means relatively stable\n",
    "        checks.append(f\"âœ… {horizon}w IC stable (CV = {cv:.2f})\")\n",
    "        break\n",
    "else:\n",
    "    checks.append(\"âš ï¸  IC shows high variability across folds\")\n",
    "\n",
    "for check in checks:\n",
    "    print(check)\n",
    "\n",
    "# Final verdict\n",
    "if all('âœ…' in check for check in checks):\n",
    "    print(\"\\nðŸŽ‰ MODEL PASSED VALIDATION - Proceed to Portfolio Construction\")\n",
    "elif any('âœ…' in check for check in checks):\n",
    "    print(\"\\nâš ï¸  MODEL PARTIALLY VALIDATED - Proceed with caution or improve features\")\n",
    "else:\n",
    "    print(\"\\nâŒ MODEL FAILED VALIDATION - Do not proceed, improve model first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ebfe1",
   "metadata": {},
   "source": [
    "## 8. Save Out-of-Sample Predictions for Portfolio Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53269c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save OOS predictions to CSV for portfolio backtest\n",
    "output_dir = '../../data/taa/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for horizon in [1, 4, 12]:\n",
    "    filepath = f'{output_dir}oos_predictions_{horizon}w.csv'\n",
    "    oos_predictions[horizon].to_csv(filepath, index=False)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "print(\"\\nâœ… Out-of-sample predictions saved for portfolio construction\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
